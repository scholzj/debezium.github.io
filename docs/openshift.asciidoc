= Deploying Debezium on OpenShift
:awestruct-layout: doc
:linkattrs:
:icons: font

The following describes how to set up the Debezium connectors for change data capture on Red Hat's https://www.openshift.com/[OpenShift] container platform.

These instructions have been tested using the https://github.com/minishift/minishift[Minishift tool]
-- allowing you to run a single node OpenShift instance locally on your machine.

You can find a complete example of this set-up using Minishift in our https://github.com/debezium/debezium-examples/tree/master/openshift[examples repository].

And if you want to get started even quicker, try out the https://learn.openshift.com/middleware/debezium-getting-started/[Debezium online learning scenario].
It starts an OpenShift cluster just for you, allowing you to take your first steps with Debezium in your browser just within a few minutes.

== Debezium Deployment

For setting up Kafka and Kafka Connect on OpenShift, a set of images provided by the https://strimzi.io/[Strimzi] project can be used, which offers "Kafka as a Service".
It consists of enterprise grade configuration files and images that bring Kafka to OpenShift.

First we install the operators and templates for the Kafka broker and Kafka Connect into our OpenShift project.
We need to create security objects as part of installation so it is necessary to switch to admin user.
If you use Minishift, you can do it with the following command:

[listing,subs="attributes",options="nowrap"]
----
oc login -u system:admin
----

We will use OpenShift project `myproject`.
It it doesn't exist yet, you can create it using following command:

[listing,subs="attributes",options="nowrap"]
----
oc new-project myproject
----

If the project already exists, you can switch to it with:

[listing,subs="attributes",options="nowrap"]
----
oc project myproject
----

First we install the Strimzi operator:

[listing,subs="attributes",options="nowrap"]
----
oc apply -f https://github.com/strimzi/strimzi-kafka-operator/releases/download/{strimzi-version}/strimzi-cluster-operator-{strimzi-version}.yaml
----

Next we will deploy a Kafka broker cluster and a Kafka Connect cluster and then create a Kafka Connect image with the Debezium connectors installed:

[listing,subs="attributes",options="nowrap"]
----
# Deploy a single instance Kafka broker
oc apply -f https://github.com/strimzi/strimzi-kafka-operator/raw/{strimzi-version}/examples/kafka/kafka-persistent-single.yaml

# Deploy a single instance of Kafka Connect with no plug-in installed
oc apply -f https://github.com/strimzi/strimzi-kafka-operator/raw/{strimzi-version}/examples/kafka-connect/kafka-connect-s2i-single-node-kafka.yaml

# Build a Debezium image
export DEBEZIUM_VERSION={debezium-version}
mkdir -p plugins && cd plugins && \
for PLUGIN in {mongodb,mysql,postgres}; do \
    curl http://central.maven.org/maven2/io/debezium/debezium-connector-$PLUGIN/$DEBEZIUM_VERSION/debezium-connector-$PLUGIN-$DEBEZIUM_VERSION-plugin.tar.gz | tar xz; \
done && \
oc start-build my-connect-cluster-connect --from-dir=. --follow && \
cd .. && rm -rf plugins
----

After a while all parts should be up and running:

[source%nowrap,bash]
----
oc get pods

NAME                                          READY   STATUS              RESTARTS   AGE
my-cluster-entity-operator-67f9d8cf68-5z9dr   3/3     Running             0          7m49s
my-cluster-kafka-0                            2/2     Running             0          8m20s
my-cluster-zookeeper-0                        2/2     Running             0          9m10s
my-connect-cluster-connect-1-7st96            1/1     Running             0          5m41s
strimzi-cluster-operator-7ff64d4b7-5zrdn      1/1     Running             0          9m23s
----

Alternatively, you can go to the "Pods" view of your OpenShift Web Console (https://myhost:8443/console/project/myproject/browse/pods) to confirm all pods are up and running:

image::/images/openshift_pods.png[width=771,align="center"]

== Verifying the Deployment

Next we are going to verify whether the deployment is correct by emulating the link:/docs/tutorial/[Debezium Tutorial] in the OpenShift environment.

First we need to start a MySQL server instance containing some example tables:

[source%nowrap,bash,subs="attributes"]
----
# Deploy pre-populated MySQL instance
oc new-app --name=mysql debezium/example-mysql:{debezium-docker-label}

# Configure credentials for the database
oc set env dc/mysql MYSQL_ROOT_PASSWORD=debezium  MYSQL_USER=mysqluser MYSQL_PASSWORD=mysqlpw
----

A new pod with MySQL server should be up and running:

[source%nowrap,bash]
----
oc get pods
NAME                             READY     STATUS      RESTARTS   AGE
...
mysql-1-4503l                    1/1       Running     0          2s
mysql-1-deploy                   1/1       Running     0          4s
...
----

Then we are going to register the Debezium MySQL connector to run against the deployed MySQL instance:

[source%nowrap,bash]
----
oc exec -i -c kafka my-cluster-kafka-0 -- curl -X POST \
    -H "Accept:application/json" \
    -H "Content-Type:application/json" \
    http://my-connect-cluster-connect-api:8083/connectors -d @- <<'EOF'

{
    "name": "inventory-connector",
    "config": {
        "connector.class": "io.debezium.connector.mysql.MySqlConnector",
        "tasks.max": "1",
        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter",
        "key.converter.schemas.enable": "false",
        "value.converter.schemas.enable": "false",
        "database.hostname": "mysql",
        "database.port": "3306",
        "database.user": "debezium",
        "database.password": "dbz",
        "database.server.id": "184054",
        "database.server.name": "dbserver1",
        "database.whitelist": "inventory",
        "database.history.kafka.bootstrap.servers": "my-cluster-kafka-bootstrap:9092",
        "database.history.kafka.topic": "schema-changes.inventory"
    }
}
EOF
----

Kafka Connect's log file should contain messages regarding execution of initial snapshot:

[source%nowrap,bash]
----
oc logs $(oc get pods -o name -l strimzi.io/name=my-connect-cluster-connect)
----

Now we can read change events for the `customers` table from the corresponding Kafka topic:

[source%nowrap,bash]
----
oc exec -it my-cluster-kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
    --bootstrap-server localhost:9092 \
    --from-beginning \
    --property print.key=true \
    --topic dbserver1.inventory.customers
----

You should see an output like the following (formatted for the sake of readability):

[source%nowrap,json]
----
# Message 1
{
    "id": 1001
}

# Message 1 Value
{
    "before": null,
    "after": {
        "id": 1001,
        "first_name": "Sally",
        "last_name": "Thomas",
        "email": "sally.thomas@acme.com"
    },
    "source": {
        "name": "dbserver1",
        "server_id": 0,
        "ts_sec": 0,
        "gtid": null,
        "file": "mysql-bin.000003",
        "pos": 154,
        "row": 0,
        "snapshot": true,
        "thread": null,
        "db": "inventory",
        "table": "customers"
    },
    "op": "c",
    "ts_ms": 1509530901446
}

# Message 2 Key
{
    "id": 1002
}

# Message 2 Value
{
    "before": null,
    "after": {
        "id": 1002,
        "first_name": "George",
        "last_name": "Bailey",
        "email": "gbailey@foobar.com"
    },
    "source": {
        "name": "dbserver1",
        "server_id": 0,
        "ts_sec": 0,
        "gtid": null,
        "file": "mysql-bin.000003",
        "pos": 154,
        "row": 0,
        "snapshot": true,
        "thread": null,
        "db": "inventory",
        "table": "customers"
    },
    "op": "c",
    "ts_ms": 1509530901446
}
...
----

Finally, let's modify some records in the `customers` table of the database:

[source%nowrap,bash]
----
oc exec -it $(oc get pods -o custom-columns=NAME:.metadata.name --no-headers -l app=mysql) \
    -- bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'

# E.g. run UPDATE customers SET email="sally.thomas@example.com" WHERE ID = 1001;
----

You should now see additional change messages in the consumer started before.

If you got any questions or requests related to running Debezium on OpenShift,
please let us know via our https://groups.google.com/forum/#!forum/debezium[user group] or in the Debezium https://gitter.im/debezium/dev[developer's chat].
